[{"/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/reportWebVitals.js":"1","/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/App.js":"2","/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/Header.js":"3","/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/Main.js":"4","/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/VideoZone.js":"5","/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/index.js":"6"},{"size":362,"mtime":1606417235686,"results":"7","hashOfConfig":"8"},{"size":210,"mtime":1606474934003,"results":"9","hashOfConfig":"8"},{"size":102,"mtime":1606485120607,"results":"10","hashOfConfig":"8"},{"size":149,"mtime":1606659882236,"results":"11","hashOfConfig":"8"},{"size":2800,"mtime":1606494356978,"results":"12","hashOfConfig":"8"},{"size":500,"mtime":1606417235685,"results":"13","hashOfConfig":"8"},{"filePath":"14","messages":"15","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"15ixull",{"filePath":"16","messages":"17","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"18","messages":"19","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"20","messages":"21","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"22","messages":"23","errorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"24"},{"filePath":"25","messages":"26","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/reportWebVitals.js",[],"/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/App.js",[],"/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/Header.js",[],"/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/Main.js",[],"/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/VideoZone.js",["27","28","29","30"],"import { useState, useEffect, useRef } from 'react';\nimport './VideoZone.css';\nimport * as faceapi from 'face-api.js';\n\nconst models = 'https://simhub.github.io/avatar-face-expression/models';\n\nexport const VideoZone = () => {\n  const [videoOn, setVideoOn] = useState(false);\n  const [animationID, setAnimationID] = useState(false);\n  const videoRef = useRef();\n  const outputRef = useRef();\n  const emotionRef = useRef();\n\n  async function initVideo() {\n    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });\n    videoRef.current.srcObject = stream;\n    setVideoOn(true);\n  }\n\n  function startStopVideo() {\n    if (videoRef.current.srcObject === null) {\n      // initVideo();\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(models),\n        faceapi.nets.faceExpressionNet.loadFromUri(models),\n      ]).then(initVideo);\n    } else {\n      videoRef.current.srcObject = null;\n      setVideoOn(false);\n    }\n  }\n\n  async function onPlay() {\n    // TODO get faceDetectorOptions\n    const options = new faceapi.TinyFaceDetectorOptions();\n    const result = await faceapi\n      .detectSingleFace(videoRef.current, options)\n      .withFaceExpressions();\n\n    if (result) {\n      const dimensions = faceapi.matchDimensions(\n        outputRef.current,\n        videoRef.current,\n        true\n      );\n      const faceLocation = {\n        x: result.detection._box._x,\n        y: result.detection._box._y,\n        width: result.detection._box._width,\n        height: result.detection._box._height,\n      };\n      const emotions = {\n        happy: 'üòÄ',\n        angry: 'üò°',\n        disgusted: 'ü§¢',\n        fearful: 'üò±',\n        neutral: 'üòê',\n        surprised: 'üò≥',\n      };\n      const currentEmotion = result.expressions.asSortedArray()[0].expression;\n      emotionRef.current.innerText = emotions[currentEmotion] || currentEmotion;\n      emotionRef.current.style.cssText = `\n        top: ${faceLocation.y - faceLocation.height / 2}px;\n        left: ${faceLocation.x + 30 /*- faceLocation.width / 4*/}px;\n        width: ${faceLocation.width}px;\n        font-size: ${faceLocation.width * 0.6}px;\n      `;\n      // faceapi.draw.drawDetections(outputRef.current, faceapi.resizeResults(result, dimensions));\n    }\n\n    requestAnimationFrame(onPlay);\n  }\n\n  return (\n    <div className=\"videozone-wrapper\">\n      <div className=\"videobox-wrapper\">\n        <video\n          onLoadedMetadata={() => onPlay(this)}\n          autoPlay\n          muted\n          playsInline\n          ref={videoRef}\n        />\n        <canvas id=\"overlay\" ref={outputRef} />\n        <div id=\"emotion\" ref={emotionRef}></div>\n      </div>\n      <button className=\"booton\" onClick={startStopVideo}>\n        {!videoOn ? 'Video On' : 'Video Off'}\n      </button>\n    </div>\n  );\n};\n","/Users/adamkusber/js/react/apps-for-practice/november_tseven/src/index.js",[],{"ruleId":"31","severity":1,"message":"32","line":1,"column":20,"nodeType":"33","messageId":"34","endLine":1,"endColumn":29},{"ruleId":"31","severity":1,"message":"35","line":9,"column":10,"nodeType":"33","messageId":"34","endLine":9,"endColumn":21},{"ruleId":"31","severity":1,"message":"36","line":9,"column":23,"nodeType":"33","messageId":"34","endLine":9,"endColumn":37},{"ruleId":"31","severity":1,"message":"37","line":41,"column":13,"nodeType":"33","messageId":"34","endLine":41,"endColumn":23},"no-unused-vars","'useEffect' is defined but never used.","Identifier","unusedVar","'animationID' is assigned a value but never used.","'setAnimationID' is assigned a value but never used.","'dimensions' is assigned a value but never used."]